We will start this chapter with general considerations about systems of partial differential equations (basic definitions, existence theorem and the notion of characteristics). More specifically, it will be seen that partial differential equations of high order can be reduced to first order systems of partial differential equations, in which fall equations of dynamics in solid mechanics (see section \ref{sec:solidMech_equations}). Then, the general concepts introduced in section \ref{sec:PDEs} will be applied in the context of solid mechanics conservation laws (section \ref{sec:characteristic_analysis}) in order to derive analytical solutions of one-dimensional problems in section \ref{sec:analytical_results}.
\subsection{General concepts}

A \textit{system of partial differential equations} can be written by means of an operator $F$ depending on sets of independent variables $x_1,...,x_N$ and dependent variables $u_1,...,u_I$:
\begin{equation}
  \label{eq:diff_operator}
  \vect{\Fc}\(x_1,...,x_N,u_1,...,u_I,\drond{u_1}{x_1},..., \drond{^Mu_I}{x_N^M}\) = \vect{0}
\end{equation}
The dimension of the system given by the operator \eqref{eq:diff_operator} is given by the size of the array $\vect{\Uc}^T=[u_1,...,u_I] \in \Rbb^I$, also referred to as the \textit{unknown vector}. The highest derivative of the unknown vector in the system defines the \textit{order of the system}. 

\paragraph{Notations:}In equation \eqref{eq:diff_operator} as in what follows, sans-serif symbols will refer to matrices while calligraphic symbols stand for column array. Furthermore, the partial derivative of an arbitrary quantity with respect to a given variable $\drond{u}{x}$ may be replaced by $u_x$ when there will be no ambiguity.

$\newline$
Making use of index notation and the convention of implicit summation over repeated indices, a system of partial differential equations can be written:
\begin{equation*}
  \sum_{k=1}^{N}\Asf_{ij}^p \drond{^p\Uc_j}{x_k^p} + \Bc_i = 0
\end{equation*}
or equivalently, in matrix form:
\begin{equation}
  \label{eq:diff_system_matrix}
  \sum_{k=1}^{N}\tens{\Asf}^p \drond{^p\vect{\Uc}}{x_k^p} + \vect{\Bc} =  \vect{0}
\end{equation}
The coefficients matrices $\tens{\Asf}^p$ and the vector $\vect{\Bc}$ may be functions of independent variables and the unknowns vector ($x_1,...,x_N,\vect{\Uc}$) leading to different types of partial differential systems. Namely, whether those terms are functions of the $x_k$ are not leads respectively to a \textit{linear system with variable coefficients} or to a \textit{linear system with constant coefficients}. The system remains \textit{linear} if $\vect{\Bc}$ depends linearly on $\vect{\Uc}$, and is \textit{semi-linear} if the relation is non-linear. Finally, if $\tens{\Asf}^p$ depends on independent variables, $\vect{\Uc}$ and its derivatives up to order $M-1$, the system is called \textit{quasi-linear}.

Solving the system of partial differential equations means that one seeks an unknown vector $\vect{\Uc}(x_1,...,x_N)$ that satisfies equations of the type of \eqref{eq:diff_system_matrix}. Geometrically speaking, the problem of finding the $I$ components of $\vect{\Uc}$ as functions of $N$ independent variables can be seen as the building of an hyper-surface surface of $\Rbb^{I+N}$, hence the term of \textit{integral surface} for $\vect{\Uc}$. Similarly to ordinary differential equations for which a one-parameter family of solutions depending on integration constants can reduce to one unique solution providing suitable conditions are used, the solution of PDEs involves arbitrary functions that can be set so that unicity is ensured. This is the object of what follows.

\paragraph{The theorem of Cauchy-Kowalevski:}
We consider here a partial differential system of dimension $I$ and order $M$ and of $N$ independent variables $x_k$. It is assumed that those system can be written:
\begin{equation}
  \label{eq:normal_form}
  \drond{^M\Uc_i}{x_1^M} = \Fc_i\(x_1,...,x_N,\Uc_1,...,\Uc_I,\drond{\Uc_1}{x_1},..., \drond{^M\Uc_I}{x_N^M} \)
\end{equation}
where the functions $\Fc_i$ do not depend on the left-hand side. In addition, initial conditions are prescribed for the derivatives of $\Uc_i$ with respect to $x_1$ up to order $M-1$ in the plane $x_1=0$, namely:
\begin{equation}
  \label{eq:IC_Cauchy}
  \begin{aligned}
    & \Uc_i(0,x_2,...,x_N) = \Gc_i(x_2,...,x_N) \\
    & ... \\
    & \drond{^{M-1}}{x_1^{M-1}}\Uc_i(0,x_2,...,x_N) = \Gc_i^{M-1}(x_2,...,x_N) 
  \end{aligned}
\end{equation}
where the $\Gc_i^p$ are arbitrary functions defined in the vicinity of the origin $(x_k=0 \:, \: k\ne 1)$.
% where $\Fc_i$ are functions that depend analytically on its variables (i.e. they can be expanded into power series in all these variables converging in a suitably small domain, which may be assumed to contain the origin x_k=0 \Uc_i=0)
The \textit{initial value problem} or \textit{Cauchy problem} consists in constructing a solution $\vect{\Uc}$ of system \eqref{eq:normal_form} that satisfies initial conditions \eqref{eq:IC_Cauchy}. The \textit{Cauchy--Kowalevski theorem} states that if functions $\Fc_i$ and $\Gc_i^p$ are analytic in the vicinity of the origin $x_k=0$, then Cauchy problem admits one and only one solution in the neighborhood of the origin (see \cite[Chapter~1]{Courant} for a proof of the theorem). % +Holmgren theorem

\paragraph{Reduction of high order PDEs to first order quasi-linear systems:} The Cauchy problem for a single partial differential equation of order $N$ can be reduced to an initial value problem for a first order quasi-linear system by means of a suitable change of variable. To illustrate this property, let us considers the following second order partial differential equation of two independent variables $(x,y)$ for the unknown $u$ (the result being extendable to more variables):
\begin{equation}
  \label{eq:2nd_order_pde}
  F(x,y,u,u_x,u_y,u_{xx},u_{yy},u_{xy})=0
\end{equation}
It is assumed that is equation can be rewritten as:
\begin{equation}
  \label{eq:2nd_order_pde_normal}
  u_{xx}= f(x,y,u,u_x,u_y,u_{yy},u_{xy})
\end{equation}
with associated initial conditions:
\begin{equation}
  \label{eq:2nd_order_pde_ICs}
  u(0,y)= g(y) \quad ; \quad u_x(0,y)= g_1(y)
\end{equation}
Then, applying the following change of variables:
\begin{equation*}
  \label{eq:change_of_variables}
  \begin{aligned}
     p = u_x \quad & ; \quad   q = u_{y} \\
     r = u_{xx} \quad  & ; \quad  s = u_{yy}\\
     t = u_{xy} \quad &
  \end{aligned}
\end{equation*}
and differentiating equation \eqref{eq:2nd_order_pde_normal} with respect to $x$:
\begin{equation*}
  \label{eq:r_x}
  u_{xxx}= f_x + f_u u_x + f_{u_x}u_{xx} + f_{u_y}u_{yx} + f_{u_{yy}}u_{yyx}+f_{u_{yx}}u_{yxx}
\end{equation*}
yields the first order partial differential system:
\begin{equation}
  \label{eq:1st_order_quasilinear_system}
  \begin{aligned}
    u_x  = p \quad & ; \quad    q_x  = p_y \\
    p_x  = r \quad &;\quad     t_x  = r_y \\
    s_x  = t_y \quad &;\quad   r_x  = f_x + f_up + f_p r + f_q p_y + f_s t_y + f_t r_y
  \end{aligned}
\end{equation}
Furthermore, from \eqref{eq:2nd_order_pde_ICs} and equation \eqref{eq:2nd_order_pde_normal}, initial conditions associated to system \eqref{eq:1st_order_quasilinear_system} can be determined:
\begin{equation}
  \label{eq:1st_order_quasilinear_system_ICs}
  \begin{aligned}
    u(0,y) = g(y) \quad & ; \quad     p(0,y) = g_1(y) \\
    q(0,y) = g'(y) \quad & ; \quad    s(0,y) = g''(y) \\
    t(0,y) = g_1'(y) \quad & ; \quad    r(0,y) = f(0,y,g(y),g_1(y),g'(y),g''(y),g_1'(y))
  \end{aligned}
\end{equation}
The solution of problem \eqref{eq:1st_order_quasilinear_system}--\eqref{eq:1st_order_quasilinear_system_ICs}  is equivalent to that of equation \eqref{eq:2nd_order_pde} \cite{Courant}.
As a consequence, in what follows we will focus on first order quasi-linear systems of partial differential equations depending on two independent variables $(t,x)$.
\subsection{Notion of characteristics -- Hyperbolic problems}
The previous discussions are based on the assumption that one can write a system of partial differential equations in a closed form for the highest derivative in one variable as in equation \eqref{eq:normal_form}. For a first order quasi-linear system in independent variables $t$ and $x$
\begin{equation}
  \label{eq:1st_order_quasilinear_syst}
  \Absf^t(x,t)\drond{\vect{\Uc}}{t} + \Absf^x(x,t) \drond{\vect{\Uc}}{x} + \vect{\Bc} = \vect{0}
\end{equation}
such an expression is possible at a given point ($x_0,t_0$) only if one of the matrices $\Absf^t$ or $\Absf^x$ is non-singular. If for instance the matrix $\Absf^x(x_0,t_0)$ is singular, the line $x=x_0$ is called a \textit{characteristic line} at the point ($x_0,t_0$) otherwise it is a \textit{free} or \textit{non-characteristic} one. In the latter case, the approaches developed above hold while in the former case, the problem is slighlty different. To see that, let us consider the first order quasi-linear PDE:
\begin{equation}
  \label{eq:1st_order_pde}
   a u_x + b u_t  = c
\end{equation}
with coefficients $a$ and $b$ such that $a^2 + b^2 \neq 0$. The solutions $u^{(i)}(x,t)$ of this equations constitute a set of surfaces in the space $(x,t,u)$ which tangent planes have normal vectors $\vect{n}^{(i)}=[u_x,u_t,-1]$ at point $(x_0,t_0,u_0)$. According to equation \eqref{eq:1st_order_pde}, those normal vectors are perpendicular to $\vect{v}=[a,b,c]$ at the same point, therefore the intersection of these planes is a straight line which direction is given by $\vect{v}$. In other words, the tangent planes of all integral surfaces at a given point belong to a pencil, called the \textit{Monge pencil}, which \textit{Monge axis} is given by the relations:
\begin{equation}
  \label{eq:monge_axis}
  \matrice{dx \\ dt \\ du} = \matrice{a \\ b \\c}
\end{equation}
At every point of the space $(x,t,u)$ the Monge axis defines \textit{characteristic line elements} which integration (equation \eqref{eq:monge_axis}) yields the \textit{characteristic curves} of the PDE. Indeed, introduction of a parameter $\xi$ along the characteristic curve yields:
\begin{equation}
  \label{eq:charac_curve}
  \ddroit{x}{\xi} = a \quad ; \quad \ddroit{t}{\xi} = b  \quad ; \quad \ddroit{u}{\xi} = c
\end{equation}
which integration gives a one-parameter family of characteristic curves. Hence, the initial problem of seeking a solution of equation \eqref{eq:1st_order_pde} is equivalent to finding a surface that is at every point normal to Monge axis. \textit{Every integral surface generated by a one-parameter family of characteristic curves is an integral surface of the PDE. Conversely, every integral surfaces is generated by a one-parameter family of characteristic \cite[Chapter~2]{Courant}} + \textit{Every characteristic curve which has one point in common with an integral surface lies entirely on the integral surface.} A characteristic curve is thus seen as a curve that starts at a point $(x_0,t_0)$ and is tangent everywhere to the integral surfaces $u(x,t)$ that passes through $u(x_0,t_0)$.

\begin{itemize}
\item Pour une edp donnée, on peut construire en chaque point $(x_0,t_0,u_0)$ une famille de courbes caractéristiques en intégrant \eqref{eq:charac_curve} et en cassant les constantes d'intégration avec les conditions initiales \textit{i.e. $x(\xi=0)=x_0 ; t(\xi=0)=t_0;u(\xi=0)=u_0$}
\item Avec les propriétés énnoncées au-dessus, chaque famille de courbes caractéristiques ainsi obtenue est intégralement inclue dans la surface intégrale $u(x,t)$ passant par $(x_0,t_0,u_0)$
\textcolor{red}{\item[?] La question n'est-elle pas de trouver une surface intégrale contenant toutes les courbes caractéristiques, auquel cas, c'est LA solution unique ?}
\item Les propriétés données au-dessus affirment également que chaque surface intégrale est générée par une famille de courbe caractéristiques...
\item Soit une courbe $\Cscr: \phi(\eta)$ tell que que $x_\eta^2 + t_\eta^2 \neq 0$, ayant une unique projection $\Cscr_0$ dans le plan $(x,t)$
\item On cherche alors dans le voisinage de $\Cscr_0$ une surface intégrale $u(,x,t)$ passant par $\Cscr$ (sous-entendu, $\Cscr$ est incluse dans $u(x,t)$ non ? oui !). Autrement dit, si on fait varier $x$ et $t$ seulement, est-ce que la solution $u(x,t)$ appartient passe aussi par $\Cscr$ quelque soit $\eta$ ($u(\eta + d\eta)=u(x(\eta+d\eta),t(\eta+d\eta))$).
\end{itemize}
Méthode:
\begin{itemize}
\item Pour chaque valeur du paramètre $\eta$ le long de $\Cscr$, on trace une courbe caractéristique en utilisant un second paramètre $\xi$. Les courbes caractéristiques ainsi obtenues sont de la forme $x=x(\xi,\eta) ; t=t(\xi,\eta) ; u=u(\xi,\eta)$ (où $\eta$ est une condition initiale non ?)
\item Ces courbes représentent une solution de l'edp si en chaque point de chacune d'elle on peut inverser les deux premières relations pour obtenir $u=u(x,t)$ et non plus en fonction de $\xi,\eta$ (d'où le jacobien différent de zéro)
\item Si on a bien bijection le long de $\Cscr$, alors $du/ds=u_x dx/ds + u_t dt/ds = a u_x + bu_t = c$ et $u(x,t)$ est bien solution de l'edp ! On est parti d'un point sur $\Cscr$ et le long des caractéristiques partant de $\Cscr$, la fonction $u(x,t)$ que l'on obtient passe également par $\Cscr$. Il est dit dans \cite{Courant} que le problem de Caucy est résolu pour la courbe initiale $\Cscr$. C'est carrément ça, on a défini dans le voisinage de la courbe $\Cscr$ une solution unique $u(x,t)$, puisqu'en chaque point $\eta$ on a tracé des courbes caractéristiques reliées à \textbf{une unique surface intégrale}.
\item Si on n'a pas bijection (partout le long de $\Cscr$, ça a pas l'air bien grave : dans ce cas $\Cscr$ est elle-même une courbe caractéristique. Dans ce cas précis, on a juste à choisir le paramètre $\eta$ de sorte à avoir $a=dx/d\eta ; b=dt/d\eta$ et quoiqu'il arrive, on a $du/d\eta=c$. On retrouve le système d'ODE des courbes caractéristiques on est donc bien sur une courbe caractéristique.
\item Alors, c'est là que ça se complique: \textit{Mais, si $\Cscr$ est une courbe caractéristique, on n'a pas seulement une, mais une infinité de surface intégrale passant par $\Cscr$ en tant que courbe initiale.} Ca, ça doit être du à l'intégration le long de l'axe de Monge. Qu'à cela ne tienne, Considérons une autre courbe $\Cscr'$ intersectant la première en un point quelconque et ayant un jacobien nul. La surface intégrale contenant $\Cscr'$ contient également $\Cscr$ et donc l'ensemble des solutions au problème aux valeurs initiales pour $\Cscr$ est déterminé par un ensemble de courbes $\Cscr'$
\item \textit{Hence, the characteristic curves are the curves in which two integral surfaces meet--branch curves--while at most one integral surface can pass through any non-characteristic curve}
\item Dans le cas où $\Cscr$ est une caractéristique, on a encore une infinité de solution
\end{itemize}

§§§§ Link between the characteristics at the begining of subsection 1.1.2 and the ones of Monge



\textbf{Sheaf or pencil of planes:} a family of planes having a common intersection line 
$\Cscr$
$\newline$
We now restrict the problem to the case of \textbf{linear systems} in one space variable in order to introduce the notions of \textit{hyperbolicity} and \textit{characteristics}, system \eqref{eq:general_pde_matrix} hence reads:
\begin{equation}
  \label{eq:1d_pde_matrix}
  \vect{\Uc}_t + \tens{\Asf}\vect{\Uc}_x + \vect{\Bc} = \vect{0} 
\end{equation}
Let us consider the Cauchy initial value problem consisting in finding $\vect{\Uc}_x$ for given initial values of $\vect{\Uc}$ (\textit{i.e. $\vect{\Uc}(x,t=0)$ is known}) on a parametrized curve $\Cc$ of the $(x,t)$ plane, namely by the function $\phi(x,t)=0$, such that equation \eqref{eq:1d_pde_matrix} is satisfied on $\Cc$. The curve $\Cc$ is assumed to satisfy the following regularity requirement $\norm{\nablav \phi} \ne 0$, where $\nablav (\bullet)$ denotes the gradient operator. Since the unknown vector is viewed as a function of $\phi(x,t)$, the following property holds (also assume $\phi_x\ne 0$):
\begin{equation}
  \label{eq:interior_derivative}
  \vect{\Uc}_x\phi_t - \vect{\Uc}_t\phi_x= \vect{0}
\end{equation}

\paragraph{Proof :} If we write the unknown vector as $\vect{\Uc}=\vect{\Wc}(\phi(x,t))$, then by using the chain rule the partial derivatives of $\vect{\Uc}$ read:
\begin{equation*}
  \vect{\Uc}_t = \vect{\Wc}' \: \phi_t \quad ; \quad \vect{\Uc}_x = \vect{\Wc}' \: \phi_x
\end{equation*}
Elimination of $\vect{\Wc}'$ then leads to:
\begin{equation*}
  \vect{\Uc}_t = \vect{\Uc}_x \frac{\phi_t}{\phi_x} 
\end{equation*}
which can be rewritten:
\begin{equation*}
  \vect{\Uc}_t \phi_x = \vect{\Uc}_x \phi_t
\end{equation*}
This ends the proof.

Equation \eqref{eq:interior_derivative} defines a relation between $\vect{\Uc}_t$ and $\vect{\Uc}_x$ that allows to write the original system \eqref{eq:1d_pde_matrix} with $\vect{\Uc}_x$ only:
\begin{equation}
  \label{eq:cauchy_IVP_for_ux}
  \( \lambda\tens{\Isf} + \tens{\Asf} \) \vect{\Uc}_x + \vect{\Bc} = \vect{0} 
\end{equation}
where $\lambda = \phi_t/\phi_x$ and $\tens{\Isf}$ is the identity matrix. It is then obvious that equation \eqref{eq:cauchy_IVP_for_ux} admits a unique solution if and only if the determinant of the system is non-zero, namely:
\begin{equation}
  \label{eq:characteristic_determinant}
  D=\abs{\lambda\tens{\Isf} + \tens{\Asf}} \ne 0
\end{equation}
where D is called the \textit{characteristic determinant} of system \eqref{eq:1d_pde_matrix}. \cite[Page~172,Page~77]{Courant}
% The complete theory of partial differential equations can be found in \cite{Courant}. In what fillows, we will restrict our attention to first order partial differential equations. 
% Suppose we are interested in describing the variation of a physical quantity depending on two independant variables which can be either space or time variables $u(x,y)$.
% \cite[Chapter~3]{Courant};\cite[Chapter~5]{Courant}
% General form of partial differential equations:
% \begin{equation}
%   \label{eq:general_pde}
%   F\(x,y,...,u,u_x,u_y,...,u_{xx},u_{xy},u_{yy},... \) = 0
% \end{equation}
% in which $F$ denotes a combination of partial derivatives of $u$ up to a given order $n$, and the subscript on $u$ stands for partial differentiation $u_x=\drond{u}{x}$. The partial differential equation \eqref{eq:general_pde} is said to be of order $n$ if the highest derivative order is of order $n$. If the function $F$ depends linearly on its variables, the partial differential equation is said to be \textit{linear}. On the other hand, if the funcion $F$ depends linearly on the highest derivatives of $u$ only then the differential equation is \textit{quasi-linear}.

% Definitions: Quasi-linear or Linear equations, order.
% The same definitions holds if the functions $F$ and $u$ are vectors:
% \begin{equation}
%   \label{eq:general_pde_system}
%   \vect{F}\(x,y,...,\vect{u},\vect{u}_x,\vect{u}_y,...,\vect{u}_{xx},\vect{u}_{xy},\vect{u}_{yy},... \) = 0
% \end{equation}
% In matrix form:
% \begin{equation}
%   \label{eq:matrix_pde_system}
%   \tens{A}^x \vect{u}_x + \tens{A}^y \vect{u}_y + \vect{b}= \vect{0}
% \end{equation}
% where the $m \times m$ matrices $\tens{A}^i$ may depend on $\vect{u}$ (quasi-linear).

% In what follows we will restrict to first order partial differential equations. Equation \eqref{eq:general_pde} may be \textit{semilinear} or \textit{linear} depending on whether the right-hand side depends on the unknown functions or not.
% Linear,quasi linear, semi linear 
% General pde form - order ?- linear quasi linear - interior differentiation




%p.172 pour les sytèmes linéaires d'EPD elliptiques et hyperboliques à deux variables indépendantes. (p.173 pour n variables)
%\cite{Toro},\cite{Leveque} pour la forme générale des systèmes hyperboliques du premier ordre. Voir \cite{Courant} pour l'étude des problèmes à plus de deux variables indépendantes qui pourrait justifier qu'on se ramène systématiquement à un problème à deux variables indépendantes pour l'analyse caractéristique.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../mainManuscript"
%%% End:
